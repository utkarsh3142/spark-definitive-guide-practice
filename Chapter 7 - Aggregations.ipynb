{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"../data/retail-data/all/*.csv\")\\\n",
    "    .coalesce(5)\n",
    "\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.count() is an action which returns the result immediately\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  541909|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below count function is transformation which is lazily evaluated\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df.select(expr(\"count(*)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count(*) includes null value count while count(column_name) doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  541909|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct\n",
    "\n",
    "df.select(count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT InvoiceNo)|\n",
      "+-------------------------+\n",
      "|                    25900|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"InvoiceNo\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(InvoiceNo)|\n",
      "+--------------------------------+\n",
      "|                           25085|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Approx count distinct is much faster\n",
    "\n",
    "df.select(approx_count_distinct(\"InvoiceNo\", 0.1)).show() # 0.1 - maximum estimation error allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min, Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|       -80995|        80995|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "df.select(min(\"Quantity\"), max(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sum(Quantity)|\n",
      "+-------------+\n",
      "|      5176450|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.select(sum(\"Quantity\")).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sumDistinct\n",
    "\n",
    "df.select(sumDistinct(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+----------------+\n",
      "|(total_purchases / total_transactions)|   avg_purchases|  mean_purchases|\n",
      "+--------------------------------------+----------------+----------------+\n",
      "|                      9.55224954743324|9.55224954743324|9.55224954743324|\n",
      "+--------------------------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, expr\n",
    "\n",
    "\n",
    "df.select(\n",
    "    count(\"Quantity\").alias(\"total_transactions\"),\n",
    "    sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    expr(\"mean(Quantity)\").alias(\"mean_purchases\"))\\\n",
    "    .selectExpr(\n",
    "    \"total_purchases/total_transactions\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_purchases\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+---------------------+\n",
      "| var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|\n",
      "+------------------+------------------+--------------------+---------------------+\n",
      "|47559.303646609056|47559.391409298754|  218.08095663447796|   218.08115785023418|\n",
      "+------------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Population statistics\n",
    "from pyspark.sql.functions import var_pop, stddev_pop\n",
    "\n",
    "# Sample statistics\n",
    "from pyspark.sql.functions import var_samp, stddev_samp\n",
    "\n",
    "df.select(var_pop(\"Quantity\"), var_samp(\"Quantity\"),\n",
    "        stddev_pop(\"Quantity\"), stddev_samp(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating to Complex Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|collect_set(Country)|collect_list(Country)|\n",
      "+--------------------+---------------------+\n",
      "|[Portugal, Italy,...| [United Kingdom, ...|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set, collect_list\n",
    "\n",
    "df.agg(collect_set(\"Country\"), collect_list(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerId|count|\n",
      "+---------+----------+-----+\n",
      "|   536846|     14573|   76|\n",
      "|   537026|     12395|   12|\n",
      "|   537883|     14437|    5|\n",
      "|   538068|     17978|   12|\n",
      "|   538279|     14952|    7|\n",
      "|   538800|     16458|   10|\n",
      "|   538942|     17346|   12|\n",
      "|  C539947|     13854|    1|\n",
      "|   540096|     13253|   16|\n",
      "|   540530|     14755|   27|\n",
      "|   541225|     14099|   19|\n",
      "|   541978|     13551|    4|\n",
      "|   542093|     17677|   16|\n",
      "|   536596|      null|    6|\n",
      "|   537252|      null|    1|\n",
      "|   538041|      null|    1|\n",
      "|   543188|     12567|   63|\n",
      "|   543590|     17377|   19|\n",
      "|  C543757|     13115|    1|\n",
      "|  C544318|     12989|    1|\n",
      "+---------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\", \"CustomerId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+\n",
      "|InvoiceNo|quan|count(Quantity)|\n",
      "+---------+----+---------------+\n",
      "|   536596|   6|              6|\n",
      "|   536938|  14|             14|\n",
      "|   537252|   1|              1|\n",
      "|   537691|  20|             20|\n",
      "|   538041|   1|              1|\n",
      "|   538184|  26|             26|\n",
      "|   538517|  53|             53|\n",
      "|   538879|  19|             19|\n",
      "|   539275|   6|              6|\n",
      "|   539630|  12|             12|\n",
      "|   540499|  24|             24|\n",
      "|   540540|  22|             22|\n",
      "|  C540850|   1|              1|\n",
      "|   540976|  48|             48|\n",
      "|   541432|   4|              4|\n",
      "|   541518| 101|            101|\n",
      "|   541783|  35|             35|\n",
      "|   542026|   9|              9|\n",
      "|   542375|   6|              6|\n",
      "|  C542604|   8|              8|\n",
      "+---------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping with expression (expr)\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(count(\"Quantity\").alias(\"quan\"),expr(\"count(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|        Country|CountDistinct|\n",
      "+---------------+-------------+\n",
      "| United Kingdom|        23494|\n",
      "|        Germany|          603|\n",
      "|         France|          461|\n",
      "|           EIRE|          360|\n",
      "|        Belgium|          119|\n",
      "|          Spain|          105|\n",
      "|    Netherlands|          101|\n",
      "|    Switzerland|           74|\n",
      "|       Portugal|           71|\n",
      "|      Australia|           69|\n",
      "|          Italy|           55|\n",
      "|        Finland|           48|\n",
      "|         Sweden|           46|\n",
      "|         Norway|           40|\n",
      "|Channel Islands|           33|\n",
      "|          Japan|           28|\n",
      "|         Poland|           24|\n",
      "|        Denmark|           21|\n",
      "|         Cyprus|           20|\n",
      "|        Austria|           19|\n",
      "+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Country\").agg(countDistinct(\"InvoiceNo\").alias(\"CountDistinct\")).orderBy(\"CountDistinct\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536596|               1.5|  1.1180339887498947|\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "|   537252|              31.0|                 0.0|\n",
      "|   537691|              8.15|   5.597097462078001|\n",
      "|   538041|              30.0|                 0.0|\n",
      "|   538184|12.076923076923077|   8.142590198943392|\n",
      "|   538517|3.0377358490566038|  2.3946659604837897|\n",
      "|   538879|21.157894736842106|  11.811070444356483|\n",
      "|   539275|              26.0|  12.806248474865697|\n",
      "|   539630|20.333333333333332|  10.225241100118645|\n",
      "|   540499|              3.75|  2.6653642652865788|\n",
      "|   540540|2.1363636363636362|  1.0572457590557278|\n",
      "|  C540850|              -1.0|                 0.0|\n",
      "|   540976|10.520833333333334|   6.496760677872902|\n",
      "|   541432|             12.25|  10.825317547305483|\n",
      "|   541518| 23.10891089108911|  20.550782784878713|\n",
      "|   541783|11.314285714285715|   8.467657556242811|\n",
      "|   542026| 7.666666666666667|   4.853406592853679|\n",
      "|   542375|               8.0|  3.4641016151377544|\n",
      "|  C542604|              -8.0|  15.173990905493518|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(expr(\"avg(Quantity)\"),expr(\"stddev_pop(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark supports three kinds of window functions: ranking functions, analytic functions,\n",
    "and aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "dfWithDate = df.withColumn(\"date\", to_date(col(\"InvoiceDate\"), \"MM/d/yyyy H:mm\"))\n",
    "dfWithDate.createOrReplaceTempView(\"dfWithDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Window Function\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Window.paritionBy.orderBy\n",
    "## Frame specification (the rowsBetween statement) states which rows will be included in the frame \n",
    "## based on its reference to the currentb input row.\n",
    "\n",
    "windowSpec = Window\\\n",
    "            .partitionBy(\"CustomerId\", \"date\")\\\n",
    "            .orderBy(desc(\"Quantity\"))\\\n",
    "            .rowsBetween(Window.unboundedPreceding, Window.currentRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running aggregation over windows\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import dense_rank, rank\n",
    "\n",
    "maxPurchaseQuantity = max(col(\"Quantity\")).over(windowSpec)\n",
    "purchaseDenseRank = dense_rank().over(windowSpec)\n",
    "purchaseRank = rank().over(windowSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|CustomerId|      date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|     12346|2011-01-18|   74215|           1|                1|              74215|\n",
      "|     12346|2011-01-18|  -74215|           2|                2|              74215|\n",
      "|     12347|2010-12-07|      36|           1|                1|                 36|\n",
      "|     12347|2010-12-07|      30|           2|                2|                 36|\n",
      "|     12347|2010-12-07|      24|           3|                3|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|       6|          17|                5|                 36|\n",
      "|     12347|2010-12-07|       6|          17|                5|                 36|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithDate.where(\"CustomerId IS NOT NULL\").orderBy(\"CustomerId\")\\\n",
    "            .select(\n",
    "                    col(\"CustomerId\"),\n",
    "                    col(\"date\"),\n",
    "                    col(\"Quantity\"),\n",
    "                    purchaseRank.alias(\"quantityRank\"),\n",
    "                    purchaseDenseRank.alias(\"quantityDenseRank\"),\n",
    "                    maxPurchaseQuantity.alias(\"maxPurchaseQuantity\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame without null values\n",
    "dfNoNull = dfWithDate.drop()\n",
    "\n",
    "dfNoNull.createOrReplaceTempView(\"dfNoNull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|      Date|       Country|total_quantity|\n",
      "+----------+--------------+--------------+\n",
      "|      null|          null|       5176450|\n",
      "|2010-12-01|United Kingdom|         23949|\n",
      "|2010-12-01|          EIRE|           243|\n",
      "|2010-12-01|       Germany|           117|\n",
      "|2010-12-01|     Australia|           107|\n",
      "|2010-12-01|   Netherlands|            97|\n",
      "|2010-12-01|        France|           449|\n",
      "|2010-12-01|          null|         26814|\n",
      "|2010-12-01|        Norway|          1852|\n",
      "|2010-12-02|       Germany|           146|\n",
      "|2010-12-02|          null|         21023|\n",
      "|2010-12-02|          EIRE|             4|\n",
      "|2010-12-02|United Kingdom|         20873|\n",
      "|2010-12-03|       Belgium|           528|\n",
      "|2010-12-03|      Portugal|            65|\n",
      "|2010-12-03|       Germany|           170|\n",
      "|2010-12-03|   Switzerland|           110|\n",
      "|2010-12-03|        Poland|           140|\n",
      "|2010-12-03|          null|         14830|\n",
      "|2010-12-03|         Spain|           400|\n",
      "+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DataFrame that includes:\n",
    "## the grand total over all dates, \n",
    "## the grand total for each date in the DataFrame,\n",
    "## and the subtotal for each country on each date in the DataFrame\n",
    "\n",
    "rolledUpDF = dfNoNull.rollup(\"Date\", \"Country\").agg(sum(\"Quantity\"))\\\n",
    "    .selectExpr(\"Date\", \"Country\", \"`sum(Quantity)` as total_quantity\")\\\n",
    "    .orderBy(\"Date\")\n",
    "\n",
    "rolledUpDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now where you see the null values is where youâ€™ll find the grand totals. A null in both rollup\n",
    "columns specifies the grand total across both of those columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pose this as a question again, can you make a table that includes the following?\n",
    "\n",
    "    The total across all dates and countries\n",
    "    The total for each date across all countries\n",
    "    The total for each country on each date\n",
    "    The total for each country across all dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+\n",
      "|Date|             Country|sum(Quantity)|\n",
      "+----+--------------------+-------------+\n",
      "|null|               Japan|        25218|\n",
      "|null|            Portugal|        16180|\n",
      "|null|           Hong Kong|         4769|\n",
      "|null|                 RSA|          352|\n",
      "|null|           Australia|        83653|\n",
      "|null|United Arab Emirates|          982|\n",
      "|null|         Unspecified|         3300|\n",
      "|null|             Finland|        10666|\n",
      "|null|             Germany|       117448|\n",
      "|null|                null|      5176450|\n",
      "|null|     Channel Islands|         9479|\n",
      "|null|           Singapore|         5234|\n",
      "|null|  European Community|          497|\n",
      "|null|             Lebanon|          386|\n",
      "|null|              Cyprus|         6317|\n",
      "|null|              Norway|        19247|\n",
      "|null|               Spain|        26824|\n",
      "|null|                 USA|         1034|\n",
      "|null|             Denmark|         8188|\n",
      "|null|      Czech Republic|          592|\n",
      "+----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "dfNoNull.cube(\"Date\", \"Country\").agg(sum(col(\"Quantity\")))\\\n",
    "                                .select(\"Date\", \"Country\", \"sum(Quantity)\").orderBy(\"Date\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = dfWithDate.groupBy(\"date\").pivot(\"Country\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- Australia_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Australia_sum(UnitPrice): double (nullable = true)\n",
      " |-- Australia_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Austria_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Austria_sum(UnitPrice): double (nullable = true)\n",
      " |-- Austria_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Bahrain_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Bahrain_sum(UnitPrice): double (nullable = true)\n",
      " |-- Bahrain_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Belgium_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Belgium_sum(UnitPrice): double (nullable = true)\n",
      " |-- Belgium_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Brazil_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Brazil_sum(UnitPrice): double (nullable = true)\n",
      " |-- Brazil_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Canada_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Canada_sum(UnitPrice): double (nullable = true)\n",
      " |-- Canada_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Channel Islands_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Channel Islands_sum(UnitPrice): double (nullable = true)\n",
      " |-- Channel Islands_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Cyprus_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Cyprus_sum(UnitPrice): double (nullable = true)\n",
      " |-- Cyprus_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Czech Republic_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Czech Republic_sum(UnitPrice): double (nullable = true)\n",
      " |-- Czech Republic_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Denmark_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Denmark_sum(UnitPrice): double (nullable = true)\n",
      " |-- Denmark_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- EIRE_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- EIRE_sum(UnitPrice): double (nullable = true)\n",
      " |-- EIRE_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- European Community_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- European Community_sum(UnitPrice): double (nullable = true)\n",
      " |-- European Community_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Finland_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Finland_sum(UnitPrice): double (nullable = true)\n",
      " |-- Finland_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- France_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- France_sum(UnitPrice): double (nullable = true)\n",
      " |-- France_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Germany_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Germany_sum(UnitPrice): double (nullable = true)\n",
      " |-- Germany_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Greece_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Greece_sum(UnitPrice): double (nullable = true)\n",
      " |-- Greece_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Hong Kong_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Hong Kong_sum(UnitPrice): double (nullable = true)\n",
      " |-- Hong Kong_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Iceland_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Iceland_sum(UnitPrice): double (nullable = true)\n",
      " |-- Iceland_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Israel_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Israel_sum(UnitPrice): double (nullable = true)\n",
      " |-- Israel_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Italy_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Italy_sum(UnitPrice): double (nullable = true)\n",
      " |-- Italy_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Japan_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Japan_sum(UnitPrice): double (nullable = true)\n",
      " |-- Japan_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Lebanon_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Lebanon_sum(UnitPrice): double (nullable = true)\n",
      " |-- Lebanon_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Lithuania_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Lithuania_sum(UnitPrice): double (nullable = true)\n",
      " |-- Lithuania_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Malta_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Malta_sum(UnitPrice): double (nullable = true)\n",
      " |-- Malta_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Netherlands_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Netherlands_sum(UnitPrice): double (nullable = true)\n",
      " |-- Netherlands_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Norway_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Norway_sum(UnitPrice): double (nullable = true)\n",
      " |-- Norway_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Poland_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Poland_sum(UnitPrice): double (nullable = true)\n",
      " |-- Poland_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Portugal_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Portugal_sum(UnitPrice): double (nullable = true)\n",
      " |-- Portugal_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- RSA_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- RSA_sum(UnitPrice): double (nullable = true)\n",
      " |-- RSA_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Saudi Arabia_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Saudi Arabia_sum(UnitPrice): double (nullable = true)\n",
      " |-- Saudi Arabia_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Singapore_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Singapore_sum(UnitPrice): double (nullable = true)\n",
      " |-- Singapore_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Spain_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Spain_sum(UnitPrice): double (nullable = true)\n",
      " |-- Spain_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Sweden_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Sweden_sum(UnitPrice): double (nullable = true)\n",
      " |-- Sweden_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Switzerland_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Switzerland_sum(UnitPrice): double (nullable = true)\n",
      " |-- Switzerland_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- USA_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- USA_sum(UnitPrice): double (nullable = true)\n",
      " |-- USA_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- United Arab Emirates_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- United Arab Emirates_sum(UnitPrice): double (nullable = true)\n",
      " |-- United Arab Emirates_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- United Kingdom_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- United Kingdom_sum(UnitPrice): double (nullable = true)\n",
      " |-- United Kingdom_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      " |-- Unspecified_sum(CAST(Quantity AS BIGINT)): long (nullable = true)\n",
      " |-- Unspecified_sum(UnitPrice): double (nullable = true)\n",
      " |-- Unspecified_sum(CAST(CustomerID AS BIGINT)): long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------+\n",
      "|      date|Australia_sum(CAST(Quantity AS BIGINT))|\n",
      "+----------+---------------------------------------+\n",
      "|2011-10-07|                                   null|\n",
      "|2011-05-06|                                   null|\n",
      "|2011-01-30|                                   null|\n",
      "|2011-11-18|                                   null|\n",
      "|2011-07-18|                                   null|\n",
      "|2011-08-21|                                   null|\n",
      "|2011-01-23|                                   null|\n",
      "|2011-07-07|                                   null|\n",
      "|2010-12-15|                                   null|\n",
      "|2011-11-14|                                   null|\n",
      "|2010-12-01|                                    107|\n",
      "|2011-04-06|                                   null|\n",
      "|2011-06-21|                                   null|\n",
      "|2011-02-21|                                   null|\n",
      "|2011-09-04|                                   null|\n",
      "|2011-08-30|                                   null|\n",
      "|2011-07-06|                                   null|\n",
      "|2011-04-27|                                   null|\n",
      "|2011-10-23|                                   null|\n",
      "|2011-08-05|                                   null|\n",
      "+----------+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.select(\"date\", \"Australia_sum(CAST(Quantity AS BIGINT))\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
